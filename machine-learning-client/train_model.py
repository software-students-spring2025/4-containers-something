"""Train a CNN model to classify ASL alphabet images."""

# pylint: disable=no-name-in-module, import-error

import os

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
from tensorflow.keras.regularizers import l2

# === CONFIG ===
DATASET_PATH = "dataset/asl_alphabet_train"
IMG_SIZE = 100
EPOCHS = 30
BATCH_SIZE = 32
MODEL_NAME = "sign_model.h5"
LABELS_FILE = "labels.txt"

print("üìÅ Scanning dataset directory...")
LABELS = sorted(
    [
        d
        for d in os.listdir(DATASET_PATH)
        if os.path.isdir(os.path.join(DATASET_PATH, d))
    ]
)
print("‚úÖ Found labels:", LABELS)

# === Save label map ===
print("üìù Saving label map to labels.txt...")
with open(LABELS_FILE, "w", encoding="utf-8") as f:
    for label in LABELS:
        f.write(f"{label}\n")
print("‚úÖ Label map saved.")

# === Data Augmentation ===
print("üîÑ Creating data generators with augmentation...")
datagen = ImageDataGenerator(
    rescale=1.0 / 255,
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.2,
)

print("üì¶ Preparing training generator...")
train_gen = datagen.flow_from_directory(
    DATASET_PATH,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode="categorical",
    subset="training",
    shuffle=True,
)

print("üì¶ Preparing validation generator...")
val_gen = datagen.flow_from_directory(
    DATASET_PATH,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode="categorical",
    subset="validation",
    shuffle=True,
)

# === Build Model ===
print("üõ†Ô∏è Building CNN model...")
model = Sequential(
    [
        Conv2D(
            16,
            (3, 3),
            activation="relu",
            input_shape=(IMG_SIZE, IMG_SIZE, 3),
            kernel_regularizer=l2(0.001),
        ),
        MaxPooling2D(2, 2),
        Dropout(0.2),
        Conv2D(32, (3, 3), activation="relu", kernel_regularizer=l2(0.001)),
        MaxPooling2D(2, 2),
        Dropout(0.3),
        Flatten(),
        Dense(64, activation="relu", kernel_regularizer=l2(0.001)),
        Dropout(0.4),
        Dense(len(LABELS), activation="softmax"),
    ]
)

model.compile(optimizer="adam", loss="categorical_crossentropy", metrics=["accuracy"])
print("‚úÖ Model compiled.")

# === Callbacks ===
checkpoint = ModelCheckpoint(MODEL_NAME, monitor="val_accuracy", save_best_only=True)
earlystop = EarlyStopping(monitor="val_loss", patience=5)

# === Train ===
print("üöÄ Starting training...")
model.fit(
    train_gen, validation_data=val_gen, epochs=EPOCHS, callbacks=[checkpoint, earlystop]
)

print(f"üéâ Training complete! Best model saved as {MODEL_NAME}")
